{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "racial-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abroad-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras import regularizers, utils\n",
    "\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.segmentation import mark_boundaries \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amazing-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_labels_path = \"labels/multiple_food.txt\"\n",
    "labels = pd.DataFrame(columns=['Filenames', 'labels'])\n",
    "categories = [str(x) for x in range(1,101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "significant-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(multiple_labels_path) as f:\n",
    "    contents = f.read().split('\\n')\n",
    "    for content in contents[1:]:\n",
    "        data = content.split(\" \")\n",
    "        filename = f'{data[0]}.jpg'\n",
    "        label = data[1:]\n",
    "        cleaned_label = [x for x in label if x != '']\n",
    "        labels = labels.append({'Filenames': filename, 'labels': cleaned_label}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civilian-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>[1, 42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>[1, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>[1, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.jpg</td>\n",
       "      <td>[1, 69, 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.jpg</td>\n",
       "      <td>[1, 36, 67, 70]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filenames           labels\n",
       "0     1.jpg          [1, 42]\n",
       "1     9.jpg          [1, 24]\n",
       "2    14.jpg          [1, 36]\n",
       "3    19.jpg      [1, 69, 70]\n",
       "4    22.jpg  [1, 36, 67, 70]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=['Filenames', 'labels'])\n",
    "# Traverse entire directory and update labels\n",
    "for root, dirs, files in os.walk(\"./UECFOOD100_CROP\"):\n",
    "    if root.startswith('./UECFOOD100_CROP/train/'):\n",
    "        label = root.split('/')[-1]\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                if len(labels.loc[labels['Filenames'] == file]) > 0:\n",
    "                    if len(train_df.loc[train_df['Filenames'] == file]) > 0:\n",
    "                        continue\n",
    "                    multi_labels = list(labels.loc[labels['Filenames'] == file].labels)[0]\n",
    "                    train_df = train_df.append({'Filenames': f'{label}/{file}', 'labels': multi_labels}, ignore_index=True) \n",
    "                else:\n",
    "                    train_df = train_df.append({'Filenames': f'{label}/{file}', 'labels': [label]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "higher-might",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61/6170.jpg</td>\n",
       "      <td>[61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61/6158.jpg</td>\n",
       "      <td>[61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61/6159.jpg</td>\n",
       "      <td>[61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61/6171.jpg</td>\n",
       "      <td>[61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61/6165.jpg</td>\n",
       "      <td>[61]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filenames labels\n",
       "0  61/6170.jpg   [61]\n",
       "1  61/6158.jpg   [61]\n",
       "2  61/6159.jpg   [61]\n",
       "3  61/6171.jpg   [61]\n",
       "4  61/6165.jpg   [61]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "educational-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['Filenames', 'labels'])\n",
    "# Traverse entire directory and update labels\n",
    "for root, dirs, files in os.walk(\"./UECFOOD100_CROP\"):\n",
    "    if root.startswith('./UECFOOD100_CROP/test/'):\n",
    "        label = root.split('/')[-1]\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                if len(labels.loc[labels['Filenames'] == file]) > 0:\n",
    "                    if len(test_df.loc[test_df['Filenames'] == file]) > 0:\n",
    "                        continue\n",
    "                    multi_labels = list(labels.loc[labels['Filenames'] == file].labels)[0]\n",
    "                    test_df = test_df.append({'Filenames': f'{label}/{file}', 'labels': multi_labels}, ignore_index=True) \n",
    "                else:\n",
    "                    test_df = test_df.append({'Filenames': f'{label}/{file}', 'labels': [label]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "endangered-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11514, 2)\n",
      "(2902, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-enzyme",
   "metadata": {},
   "source": [
    "Reference: https://vijayabhaskar96.medium.com/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "liked-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9212 validated image filenames belonging to 100 classes.\n",
      "Found 2302 validated image filenames belonging to 100 classes.\n",
      "Found 2902 validated image filenames belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "# Multilabel - train\n",
    "datagen=ImageDataGenerator(rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2)\n",
    "test_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"./UECFOOD100_CROP/train/\",\n",
    "    x_col=\"Filenames\",\n",
    "    y_col=\"labels\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=categories,\n",
    "    target_size=(128,128),\n",
    "    subset=\"training\")\n",
    "\n",
    "validation_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"./UECFOOD100_CROP/train\",\n",
    "    x_col=\"Filenames\",\n",
    "    y_col=\"labels\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=categories,\n",
    "    target_size=(128,128),\n",
    "    subset=\"validation\")\n",
    "\n",
    "test_generator=test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=\"./UECFOOD100_CROP/test\",\n",
    "    x_col=\"Filenames\",\n",
    "    y_col=\"labels\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "emerging-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-kansas",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fantastic-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, None, None, 3 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, None, None, 3 96          conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, None, None, 3 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, None, None, 3 9216        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, None, None, 3 96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, None, None, 3 0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, None, None, 6 18432       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, None, None, 6 192         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, None, None, 6 0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, None, None, 6 0           activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, None, None, 8 240         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, None, None, 8 0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, None, None, 1 138240      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, None, None, 1 576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, None, None, 1 0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, None, None, 1 0           activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, None, None, 6 192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, None, None, 6 0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, None, None, 9 55296       activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, None, None, 4 144         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, None, None, 9 288         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, None, None, 4 0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, None, None, 9 0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, None, None, 1 0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, None, None, 6 76800       activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, None, None, 9 82944       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, None, None, 6 192         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, None, None, 6 192         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, None, None, 9 288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, None, None, 3 96          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, None, None, 6 0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, None, None, 6 0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, None, None, 9 0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, None, None, 3 0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_287[0][0]             \n",
      "                                                                 activation_289[0][0]             \n",
      "                                                                 activation_292[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, None, None, 6 192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, None, None, 6 0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, None, None, 9 55296       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, None, None, 4 144         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, None, None, 9 288         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, None, None, 4 0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, None, None, 9 0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, None, None, 6 76800       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, None, None, 9 82944       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, None, None, 6 192         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, None, None, 6 192         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, None, None, 9 288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, None, None, 6 192         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, None, None, 6 0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, None, None, 6 0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, None, None, 9 0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, None, None, 6 0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_294[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_299[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, None, None, 6 192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, None, None, 6 0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, None, None, 9 55296       activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, None, None, 4 144         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, None, None, 9 288         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, None, None, 4 0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, None, None, 9 0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, None, None, 6 76800       activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, None, None, 9 82944       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, None, None, 6 192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, None, None, 6 192         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, None, None, 9 288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, None, None, 6 192         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, None, None, 6 0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, None, None, 6 0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, None, None, 9 0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, None, None, 6 0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_301[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, None, None, 6 192         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, None, None, 6 0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, None, None, 9 55296       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, None, None, 9 288         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, None, None, 9 0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, None, None, 9 82944       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, None, None, 3 1152        conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, None, None, 9 288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, None, None, 3 0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, None, None, 9 0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_308[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, None, None, 1 384         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, None, None, 1 0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, None, None, 1 114688      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, None, None, 1 384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, None, None, 1 0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, None, None, 1 114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, None, None, 1 384         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, None, None, 1 384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, None, None, 1 0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, None, None, 1 0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, None, None, 1 114688      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, None, None, 1 114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, None, None, 1 384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, None, None, 1 384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, None, None, 1 0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, None, None, 1 0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, None, None, 1 172032      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, None, None, 1 172032      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, None, None, 1 576         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, None, None, 1 576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, None, None, 1 576         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, None, None, 1 576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, None, None, 1 0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, None, None, 1 0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, None, None, 1 0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, None, None, 1 0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_312[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "                                                                 activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, None, None, 1 480         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, None, None, 1 0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, None, None, 1 179200      activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, None, None, 1 480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, None, None, 1 0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, None, None, 1 179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, None, None, 1 480         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, None, None, 1 480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, None, None, 1 0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, None, None, 1 0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, None, None, 1 179200      activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, None, None, 1 179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, None, None, 1 480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, None, None, 1 480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, None, None, 1 0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, None, None, 1 0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, None, None, 1 215040      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, None, None, 1 215040      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, None, None, 1 576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, None, None, 1 576         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, None, None, 1 576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, None, None, 1 576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, None, None, 1 0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, None, None, 1 0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, None, None, 1 0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, None, None, 1 0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_322[0][0]             \n",
      "                                                                 activation_325[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, None, None, 1 480         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, None, None, 1 0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, None, None, 1 179200      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, None, None, 1 480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, None, None, 1 0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, None, None, 1 179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, None, None, 1 480         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, None, None, 1 480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, None, None, 1 0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, None, None, 1 0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, None, None, 1 179200      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, None, None, 1 179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, None, None, 1 480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, None, None, 1 480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, None, None, 1 0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, None, None, 1 0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, None, None, 1 215040      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, None, None, 1 215040      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, None, None, 1 576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, None, None, 1 576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, None, None, 1 576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, None, None, 1 576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, None, None, 1 0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, None, None, 1 0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, None, None, 1 0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, None, None, 1 0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_332[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, None, None, 1 576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, None, None, 1 0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, None, None, 1 258048      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, None, None, 1 576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, None, None, 1 0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, None, None, 1 258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, None, None, 1 576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, None, None, 1 576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, None, None, 1 0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, None, None, 1 0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, None, None, 1 258048      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, None, None, 1 258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, None, None, 1 576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, None, None, 1 576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, None, None, 1 0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, None, None, 1 0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, None, None, 1 258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, None, None, 1 258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, None, None, 1 576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, None, None, 1 576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, None, None, 1 576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, None, None, 1 576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, None, None, 1 0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, None, None, 1 0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, None, None, 1 0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, None, None, 1 0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_342[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, None, None, 1 576         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, None, None, 1 0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, None, None, 1 258048      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, None, None, 1 576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, None, None, 1 0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, None, None, 1 258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, None, None, 1 576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, None, None, 1 576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, None, None, 1 0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, None, None, 1 0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, None, None, 3 552960      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, None, None, 1 331776      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, None, None, 3 960         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, None, None, 1 576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, None, None, 3 0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, None, None, 1 0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_353[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, None, None, 4 1344        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, None, None, 4 0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, None, None, 3 1548288     activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, None, None, 3 1152        conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, None, None, 3 1152        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, None, None, 3 0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, None, None, 3 0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, None, None, 3 442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, None, None, 3 442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, None, None, 3 442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, None, None, 3 442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, None, None, 3 1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, None, None, 3 1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, None, None, 3 1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, None, None, 3 1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, None, None, 3 960         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, None, None, 3 0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, None, None, 3 0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, None, None, 3 0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, None, None, 3 0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, None, None, 1 576         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, None, None, 3 0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_360[0][0]             \n",
      "                                                                 activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 7 0           activation_364[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, None, None, 1 0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_358[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, None, None, 4 1344        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, None, None, 4 0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, None, None, 3 1548288     activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, None, None, 3 1152        conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, None, None, 3 1152        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, None, None, 3 0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, None, None, 3 0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, None, None, 3 442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, None, None, 3 442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, None, None, 3 442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, None, None, 3 442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, None, None, 3 1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, None, None, 3 1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, None, None, 3 1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, None, None, 3 1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, None, None, 3 960         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, None, None, 3 0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, None, None, 3 0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, None, None, 3 0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, None, None, 3 0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, None, None, 1 576         conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, None, None, 3 0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_369[0][0]             \n",
      "                                                                 activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, None, 7 0           activation_373[0][0]             \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, None, None, 1 0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_367[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 2048)         8192        global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2048)         4196352     batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2048)         4196352     dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2048)         4196352     dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 100)          204900      dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 34,604,932\n",
      "Trainable params: 12,798,052\n",
      "Non-trainable params: 21,806,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "output = Dense(100,kernel_regularizer=regularizers.l2(0.005), activation='sigmoid')(x)\n",
    "# output = Dense(100,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "model = Model(inputs=inception.input, outputs=output)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate=0.001), metrics = ['categorical_accuracy', 'binary_accuracy', \n",
    "                                                                             'top_k_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-transsexual",
   "metadata": {},
   "source": [
    "Baseline train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numeric-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 154s 534ms/step - loss: 1.7739 - categorical_accuracy: 0.0047 - binary_accuracy: 0.4771 - top_k_categorical_accuracy: 0.0329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7738800048828125,\n",
       " 0.004667824599891901,\n",
       " 0.47711682319641113,\n",
       " 0.032891880720853806]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "valuable-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 43s 475ms/step - loss: 1.7746 - categorical_accuracy: 0.0079 - binary_accuracy: 0.4746 - top_k_categorical_accuracy: 0.0438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.774566888809204,\n",
       " 0.007925568148493767,\n",
       " 0.47456932067871094,\n",
       " 0.043762922286987305]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "warming-essex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "288/288 [==============================] - 247s 858ms/step - loss: 0.1595 - categorical_accuracy: 0.1592 - binary_accuracy: 0.9849 - top_k_categorical_accuracy: 0.3545 - val_loss: 0.0897 - val_categorical_accuracy: 0.0456 - val_binary_accuracy: 0.9875 - val_top_k_categorical_accuracy: 0.0743 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "288/288 [==============================] - 235s 816ms/step - loss: 0.0585 - categorical_accuracy: 0.2485 - binary_accuracy: 0.9872 - top_k_categorical_accuracy: 0.5144 - val_loss: 0.0912 - val_categorical_accuracy: 0.0469 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.0912 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "288/288 [==============================] - 254s 881ms/step - loss: 0.0544 - categorical_accuracy: 0.2890 - binary_accuracy: 0.9874 - top_k_categorical_accuracy: 0.5752 - val_loss: 0.0940 - val_categorical_accuracy: 0.0569 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.0830 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "288/288 [==============================] - 280s 974ms/step - loss: 0.0523 - categorical_accuracy: 0.3152 - binary_accuracy: 0.9875 - top_k_categorical_accuracy: 0.6120 - val_loss: 0.0896 - val_categorical_accuracy: 0.0599 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.1021 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "288/288 [==============================] - 238s 828ms/step - loss: 0.0508 - categorical_accuracy: 0.3356 - binary_accuracy: 0.9878 - top_k_categorical_accuracy: 0.6293 - val_loss: 0.0919 - val_categorical_accuracy: 0.0582 - val_binary_accuracy: 0.9862 - val_top_k_categorical_accuracy: 0.1021 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "288/288 [==============================] - 244s 846ms/step - loss: 0.0495 - categorical_accuracy: 0.3452 - binary_accuracy: 0.9880 - top_k_categorical_accuracy: 0.6456 - val_loss: 0.0924 - val_categorical_accuracy: 0.0608 - val_binary_accuracy: 0.9860 - val_top_k_categorical_accuracy: 0.0977 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "288/288 [==============================] - 254s 884ms/step - loss: 0.0486 - categorical_accuracy: 0.3632 - binary_accuracy: 0.9881 - top_k_categorical_accuracy: 0.6592 - val_loss: 0.0983 - val_categorical_accuracy: 0.0465 - val_binary_accuracy: 0.9862 - val_top_k_categorical_accuracy: 0.1030 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "288/288 [==============================] - 259s 900ms/step - loss: 0.0481 - categorical_accuracy: 0.3764 - binary_accuracy: 0.9882 - top_k_categorical_accuracy: 0.6667 - val_loss: 0.0958 - val_categorical_accuracy: 0.0669 - val_binary_accuracy: 0.9862 - val_top_k_categorical_accuracy: 0.1121 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0470 - categorical_accuracy: 0.3910 - binary_accuracy: 0.9882 - top_k_categorical_accuracy: 0.6809\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "288/288 [==============================] - 249s 863ms/step - loss: 0.0470 - categorical_accuracy: 0.3910 - binary_accuracy: 0.9882 - top_k_categorical_accuracy: 0.6809 - val_loss: 0.0959 - val_categorical_accuracy: 0.0634 - val_binary_accuracy: 0.9860 - val_top_k_categorical_accuracy: 0.1116 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "288/288 [==============================] - 244s 849ms/step - loss: 0.0428 - categorical_accuracy: 0.4318 - binary_accuracy: 0.9889 - top_k_categorical_accuracy: 0.7297 - val_loss: 0.0879 - val_categorical_accuracy: 0.0725 - val_binary_accuracy: 0.9859 - val_top_k_categorical_accuracy: 0.1164 - lr: 5.0000e-04\n",
      "Epoch 11/25\n",
      "288/288 [==============================] - 238s 826ms/step - loss: 0.0415 - categorical_accuracy: 0.4450 - binary_accuracy: 0.9891 - top_k_categorical_accuracy: 0.7334 - val_loss: 0.0932 - val_categorical_accuracy: 0.0495 - val_binary_accuracy: 0.9857 - val_top_k_categorical_accuracy: 0.1051 - lr: 5.0000e-04\n",
      "Epoch 12/25\n",
      "288/288 [==============================] - 233s 810ms/step - loss: 0.0412 - categorical_accuracy: 0.4478 - binary_accuracy: 0.9891 - top_k_categorical_accuracy: 0.7438 - val_loss: 0.0892 - val_categorical_accuracy: 0.0582 - val_binary_accuracy: 0.9866 - val_top_k_categorical_accuracy: 0.1225 - lr: 5.0000e-04\n",
      "Epoch 13/25\n",
      "288/288 [==============================] - 240s 834ms/step - loss: 0.0401 - categorical_accuracy: 0.4606 - binary_accuracy: 0.9893 - top_k_categorical_accuracy: 0.7587 - val_loss: 0.0907 - val_categorical_accuracy: 0.0652 - val_binary_accuracy: 0.9853 - val_top_k_categorical_accuracy: 0.1112 - lr: 5.0000e-04\n",
      "Epoch 14/25\n",
      "288/288 [==============================] - 237s 823ms/step - loss: 0.0397 - categorical_accuracy: 0.4618 - binary_accuracy: 0.9894 - top_k_categorical_accuracy: 0.7679 - val_loss: 0.0895 - val_categorical_accuracy: 0.0660 - val_binary_accuracy: 0.9858 - val_top_k_categorical_accuracy: 0.1229 - lr: 5.0000e-04\n",
      "Epoch 15/25\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0392 - categorical_accuracy: 0.4681 - binary_accuracy: 0.9895 - top_k_categorical_accuracy: 0.7634\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "288/288 [==============================] - 233s 810ms/step - loss: 0.0392 - categorical_accuracy: 0.4681 - binary_accuracy: 0.9895 - top_k_categorical_accuracy: 0.7634 - val_loss: 0.0907 - val_categorical_accuracy: 0.0630 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.1129 - lr: 5.0000e-04\n",
      "Epoch 16/25\n",
      "288/288 [==============================] - 234s 813ms/step - loss: 0.0369 - categorical_accuracy: 0.4992 - binary_accuracy: 0.9900 - top_k_categorical_accuracy: 0.7883 - val_loss: 0.0895 - val_categorical_accuracy: 0.0595 - val_binary_accuracy: 0.9860 - val_top_k_categorical_accuracy: 0.1251 - lr: 2.5000e-04\n",
      "Epoch 17/25\n",
      "288/288 [==============================] - 229s 795ms/step - loss: 0.0362 - categorical_accuracy: 0.4973 - binary_accuracy: 0.9900 - top_k_categorical_accuracy: 0.7977 - val_loss: 0.0905 - val_categorical_accuracy: 0.0669 - val_binary_accuracy: 0.9857 - val_top_k_categorical_accuracy: 0.1225 - lr: 2.5000e-04\n",
      "Epoch 18/25\n",
      "288/288 [==============================] - 232s 804ms/step - loss: 0.0358 - categorical_accuracy: 0.5092 - binary_accuracy: 0.9902 - top_k_categorical_accuracy: 0.7981 - val_loss: 0.0894 - val_categorical_accuracy: 0.0691 - val_binary_accuracy: 0.9861 - val_top_k_categorical_accuracy: 0.1182 - lr: 2.5000e-04\n",
      "Epoch 19/25\n",
      "288/288 [==============================] - 234s 811ms/step - loss: 0.0354 - categorical_accuracy: 0.5058 - binary_accuracy: 0.9902 - top_k_categorical_accuracy: 0.8034 - val_loss: 0.0896 - val_categorical_accuracy: 0.0595 - val_binary_accuracy: 0.9859 - val_top_k_categorical_accuracy: 0.1173 - lr: 2.5000e-04\n",
      "Epoch 20/25\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0349 - categorical_accuracy: 0.5161 - binary_accuracy: 0.9903 - top_k_categorical_accuracy: 0.8064Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "288/288 [==============================] - 231s 801ms/step - loss: 0.0349 - categorical_accuracy: 0.5161 - binary_accuracy: 0.9903 - top_k_categorical_accuracy: 0.8064 - val_loss: 0.0935 - val_categorical_accuracy: 0.0556 - val_binary_accuracy: 0.9856 - val_top_k_categorical_accuracy: 0.1147 - lr: 2.5000e-04\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "#early stopping to monitor the validation loss and avoid overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "#reducing learning rate on plateau\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience= 5, factor= 0.5, min_lr= 1e-6, verbose=1)\n",
    "\n",
    "#With training and validation data\n",
    "history1 = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=25,\n",
    "                    verbose=True,  \n",
    "                    callbacks=[early_stop, rlrop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-eclipse",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "differential-mileage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_381 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               204900    \n",
      "=================================================================\n",
      "Total params: 28,561,316\n",
      "Trainable params: 13,845,604\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "x = Dense(2048,activation='relu')(x)\n",
    "\n",
    "output = Dense(100,kernel_regularizer=regularizers.l2(0.005), activation='sigmoid')(x)\n",
    "# output = Dense(100,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate=0.001), metrics = ['categorical_accuracy', 'binary_accuracy', \n",
    "                                                                             'top_k_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "laughing-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 997s 3s/step - loss: 1.6557 - categorical_accuracy: 0.0151 - binary_accuracy: 0.4830 - top_k_categorical_accuracy: 0.0687\n",
      "91/91 [==============================] - 351s 4s/step - loss: 1.6562 - categorical_accuracy: 0.0107 - binary_accuracy: 0.4815 - top_k_categorical_accuracy: 0.0593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6562414169311523,\n",
       " 0.010682287625968456,\n",
       " 0.48147135972976685,\n",
       " 0.05926946923136711]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "indie-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "288/288 [==============================] - 1448s 5s/step - loss: 0.1571 - categorical_accuracy: 0.0992 - binary_accuracy: 0.9848 - top_k_categorical_accuracy: 0.2378 - val_loss: 0.1057 - val_categorical_accuracy: 0.0556 - val_binary_accuracy: 0.9876 - val_top_k_categorical_accuracy: 0.1043 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "288/288 [==============================] - 1106s 4s/step - loss: 0.0645 - categorical_accuracy: 0.1446 - binary_accuracy: 0.9871 - top_k_categorical_accuracy: 0.3193 - val_loss: 0.0875 - val_categorical_accuracy: 0.0456 - val_binary_accuracy: 0.9872 - val_top_k_categorical_accuracy: 0.0821 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "288/288 [==============================] - 1089s 4s/step - loss: 0.0594 - categorical_accuracy: 0.1761 - binary_accuracy: 0.9872 - top_k_categorical_accuracy: 0.3998 - val_loss: 0.0871 - val_categorical_accuracy: 0.0582 - val_binary_accuracy: 0.9876 - val_top_k_categorical_accuracy: 0.0895 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "288/288 [==============================] - 1052s 4s/step - loss: 0.0562 - categorical_accuracy: 0.2133 - binary_accuracy: 0.9873 - top_k_categorical_accuracy: 0.4587 - val_loss: 0.0889 - val_categorical_accuracy: 0.0560 - val_binary_accuracy: 0.9872 - val_top_k_categorical_accuracy: 0.0825 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "288/288 [==============================] - 1056s 4s/step - loss: 0.0545 - categorical_accuracy: 0.2366 - binary_accuracy: 0.9874 - top_k_categorical_accuracy: 0.5004 - val_loss: 0.0879 - val_categorical_accuracy: 0.0339 - val_binary_accuracy: 0.9868 - val_top_k_categorical_accuracy: 0.0908 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "288/288 [==============================] - 1000s 3s/step - loss: 0.0530 - categorical_accuracy: 0.2588 - binary_accuracy: 0.9875 - top_k_categorical_accuracy: 0.5341 - val_loss: 0.0870 - val_categorical_accuracy: 0.0656 - val_binary_accuracy: 0.9873 - val_top_k_categorical_accuracy: 0.0943 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "288/288 [==============================] - 874s 3s/step - loss: 0.0518 - categorical_accuracy: 0.2795 - binary_accuracy: 0.9876 - top_k_categorical_accuracy: 0.5594 - val_loss: 0.0908 - val_categorical_accuracy: 0.0613 - val_binary_accuracy: 0.9870 - val_top_k_categorical_accuracy: 0.1064 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "288/288 [==============================] - 873s 3s/step - loss: 0.0503 - categorical_accuracy: 0.3048 - binary_accuracy: 0.9878 - top_k_categorical_accuracy: 0.5828 - val_loss: 0.0902 - val_categorical_accuracy: 0.0565 - val_binary_accuracy: 0.9869 - val_top_k_categorical_accuracy: 0.0990 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "288/288 [==============================] - 874s 3s/step - loss: 0.0493 - categorical_accuracy: 0.3174 - binary_accuracy: 0.9880 - top_k_categorical_accuracy: 0.5994 - val_loss: 0.0865 - val_categorical_accuracy: 0.0682 - val_binary_accuracy: 0.9869 - val_top_k_categorical_accuracy: 0.0995 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "288/288 [==============================] - 871s 3s/step - loss: 0.0483 - categorical_accuracy: 0.3275 - binary_accuracy: 0.9880 - top_k_categorical_accuracy: 0.6158 - val_loss: 0.0904 - val_categorical_accuracy: 0.0660 - val_binary_accuracy: 0.9871 - val_top_k_categorical_accuracy: 0.1064 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "288/288 [==============================] - 875s 3s/step - loss: 0.0475 - categorical_accuracy: 0.3400 - binary_accuracy: 0.9882 - top_k_categorical_accuracy: 0.6278 - val_loss: 0.0937 - val_categorical_accuracy: 0.0652 - val_binary_accuracy: 0.9869 - val_top_k_categorical_accuracy: 0.0977 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "288/288 [==============================] - 874s 3s/step - loss: 0.0468 - categorical_accuracy: 0.3574 - binary_accuracy: 0.9883 - top_k_categorical_accuracy: 0.6452 - val_loss: 0.0904 - val_categorical_accuracy: 0.0500 - val_binary_accuracy: 0.9866 - val_top_k_categorical_accuracy: 0.0982 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "288/288 [==============================] - 873s 3s/step - loss: 0.0461 - categorical_accuracy: 0.3656 - binary_accuracy: 0.9886 - top_k_categorical_accuracy: 0.6501 - val_loss: 0.0914 - val_categorical_accuracy: 0.0669 - val_binary_accuracy: 0.9867 - val_top_k_categorical_accuracy: 0.1043 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0450 - categorical_accuracy: 0.3851 - binary_accuracy: 0.9886 - top_k_categorical_accuracy: 0.6683\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "288/288 [==============================] - 871s 3s/step - loss: 0.0450 - categorical_accuracy: 0.3851 - binary_accuracy: 0.9886 - top_k_categorical_accuracy: 0.6683 - val_loss: 0.0952 - val_categorical_accuracy: 0.0569 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.0960 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "288/288 [==============================] - 872s 3s/step - loss: 0.0411 - categorical_accuracy: 0.4229 - binary_accuracy: 0.9893 - top_k_categorical_accuracy: 0.7170 - val_loss: 0.0917 - val_categorical_accuracy: 0.0504 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.1090 - lr: 5.0000e-04\n",
      "Epoch 16/25\n",
      "288/288 [==============================] - 870s 3s/step - loss: 0.0399 - categorical_accuracy: 0.4324 - binary_accuracy: 0.9895 - top_k_categorical_accuracy: 0.7298 - val_loss: 0.0907 - val_categorical_accuracy: 0.0643 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.1169 - lr: 5.0000e-04\n",
      "Epoch 17/25\n",
      "288/288 [==============================] - 870s 3s/step - loss: 0.0391 - categorical_accuracy: 0.4481 - binary_accuracy: 0.9896 - top_k_categorical_accuracy: 0.7427 - val_loss: 0.0939 - val_categorical_accuracy: 0.0613 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.1086 - lr: 5.0000e-04\n",
      "Epoch 18/25\n",
      "288/288 [==============================] - 870s 3s/step - loss: 0.0384 - categorical_accuracy: 0.4519 - binary_accuracy: 0.9897 - top_k_categorical_accuracy: 0.7485 - val_loss: 0.0946 - val_categorical_accuracy: 0.0578 - val_binary_accuracy: 0.9863 - val_top_k_categorical_accuracy: 0.1095 - lr: 5.0000e-04\n",
      "Epoch 19/25\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0376 - categorical_accuracy: 0.4657 - binary_accuracy: 0.9900 - top_k_categorical_accuracy: 0.7549Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "288/288 [==============================] - 869s 3s/step - loss: 0.0376 - categorical_accuracy: 0.4657 - binary_accuracy: 0.9900 - top_k_categorical_accuracy: 0.7549 - val_loss: 0.0918 - val_categorical_accuracy: 0.0630 - val_binary_accuracy: 0.9865 - val_top_k_categorical_accuracy: 0.1199 - lr: 5.0000e-04\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "#With training and validation data\n",
    "history2 = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=25,\n",
    "                    verbose=True,  \n",
    "                    callbacks=[early_stop, rlrop]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
